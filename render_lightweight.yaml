services:
  - type: web
    name: local-llm-api-lightweight
    env: python
    buildCommand: bash setup_lightweight.sh
    startCommand: uvicorn main_lightweight:app --host 0.0.0.0 --port $PORT
    plan: starter  # Free tier - 512MB RAM
    envVars:
      - key: TRANSFORMERS_CACHE
        value: /tmp/hf-cache
      - key: TF_FORCE_GPU_ALLOW_GROWTH
        value: "true"
      - key: TF_CPP_MIN_LOG_LEVEL
        value: "2"  # Reduce TensorFlow logging
      - key: PYTHONUNBUFFERED
        value: "1" 